{
  "model": {
    "model_path": "./model",
    "max_seq_length": 2048,
    "load_in_4bit": false
  },
  
  "generation": {
    "max_new_tokens": 2048,
    "use_cache": true
  },
  
  "logging": {
    "verbosity": "error",
    "enable_streaming": true
  }
}
