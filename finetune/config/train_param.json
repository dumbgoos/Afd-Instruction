{
  "task": "class",
  "cuda_visible_devices": "0",
  "seed": 0,
  "max_seq_length": 2048,

  "paths": {
    "base_model": "meta-llama/Meta-Llama-3-8B",
    "data_file": "./data/toy.jsonl",
    "output_dir": "./output",
    "save_dir": "./model"
  },

  "chat_template": {
    "template": "chatml",
    "mapping": {"role": "from", "content": "value", "user": "human", "assistant": "gpt"}
  },

  "unsloth": {
    "load_in_4bit": true,
    "dtype": null,
    "use_gradient_checkpointing": "unsloth"
  },

  "lora": {
    "r": 16,
    "lora_alpha": 16,
    "lora_dropout": 0.0,
    "use_rslora": true,
    "target_modules": [
      "q_proj", "k_proj", "v_proj",
      "up_proj", "down_proj", "o_proj", "gate_proj"
    ]
  },

  "training": {
    "learning_rate": 2e-4,
    "lr_scheduler_type": "linear",
    "per_device_train_batch_size": 2,
    "gradient_accumulation_steps": 4,
    "num_train_epochs": 3,
    "weight_decay": 0.01,
    "warmup_steps": 5,
    "logging_steps": 1,
    "optim": "adamw_8bit",
    "packing": false,
    "dataset_num_proc": 1
  },

  "reporting": {
    "use_neptune": false,
    "project": "project_name/experiment_name",
    "tags": ["unsloth", "sft", "llama3"],
    "log_interval_steps": 1,
    "upload_config": true,
    "mode": "async"
  }
}